## 模型的安全保护
AI服务提供商在本地完成模型训练和调优后，将模型部署到第三方外包平台上（如终端设备、边缘设备和云服务器）来提供推理服务。由于AI模型的设计和训练需要投入大量时间、数据和算力，如何保护模型的知识产权（包括模型结构和参数等信息），防止模型在部署过程中的传输、存储以及运行环节被窃取，已经成为服务/模型提供商最为关心的问题之一。

### 概述
模型的安全保护可以分为静态保护和动态保护两个方面。静态保护指的是模型在传输和存储时的保护，目前业界普遍采用的是基于文件加密的模型保护方案，AI模型文件在传输和存储时加密，执行推理前在内存中解密。在整个推理过程中，模型在内存中都是明文的，存在被敌手从内存中转储的风险。动态保护指的是模型在运行时的保护，目前业界已有的模型运行时保护方案主要有以下三个技术路线：一是基于TEE（Trusted execution environment）的模型保护方案，TEE通常指的是通过可信硬件隔离出来的一个“安全区”，AI模型文件在非安全区加密存储和传输，在安全区中解密影响。该方案在CPU上的推理时延较小，但依赖特定可信硬件，有一定的部署难度。此外，受硬件资源约束，难以保护大规模深度模型，且目前仍无法有效支持异构硬件加速。二是基于密态计算的保护方案，该方案基于密码学方法（如同态加密、多方安全计算等），保证模型在传输、存储和运行过程中始终保持密文状态。该方案不依赖特定硬件，但面临非常大的计算或通信开销问题，且无法保护模型结构信息。三是基于混淆的模型保护方案，该方案主要通过对模型的计算逻辑进行加扰，使得敌手即使能获取到模型也无法理解。与前两种技术路线相比，该方案仅带来较小的性能开销，且精度损失很低，同时，不依赖特定硬件，可支持大模型的保护。下面将重点介绍基于混淆的模型保护技术。

### 模型混淆
该技术可以自动混淆明文AI模型的计算逻辑，使得攻击者即使能在传输和存储时获取到模型也无法理解；且支持模型混淆态执行，保证模型运行时的机密性且不影响模型执行结果。同时，仅带来较小的推理性能开销。模型混淆技术主要包含以下几个步骤：

![模型混淆执行示意图](../img/ch08/model_obfuscate.png)
:width:`400px`
:label:`ch08-fig-model_obfuscate`

1，对训练好的明文模型，进行模型混淆（包括网络结构混淆、算子类型混淆、权重混淆），混淆产物包括混淆模型和混淆算子库。混淆后的模型结构、算子名称以及模型权重都与原模型不同，攻击者即使窃取到混淆后的模型，也不能理解原模型结构，保证了模型传输过程中的机密性；

2，将混淆后的模型和混淆算子库部署到使用者的环境，混淆算子库中包含了混淆模型中每个节点的计算逻辑（混淆算子库已做代码混淆处理，防止逆向工程）；

3，利用混淆模型执行装置，解析混淆模型，调用混淆算子库中的算子，进行推理任务，保证了模型在推理过程中的机密性。
