# 分布式训练

随着机器学习的进一步发展，科学家们设计出更大型、更多功能的机器学习模型（例如GPT-3）。这种模型含有大量参数和复杂的结构。他们因此需要海量的计算和内存资源。单个机器上有限的资源无法满足训练大型机器学习模型的需求。因此，需要设计分布式训练系统，从而将一个机器学习模型任务拆分成多个子任务，并将子任务分发给多个计算节点，解决资源瓶颈。

本章引入分布式机器学习系统的相关概念、设计挑战、系统实现和实例研究。首先讨论分布式训练系统的定义、设计动机和好处。然后进一步讨论常见的分布式训练方法：数据并行、模型并行和流水线并行。在实际中，这些分布式训练方法会被集合通信（Collective Communication）或者参数服务器（Parameter Servers）实现。不同的系统实现具有各自的优势和劣势。

本章的学习目标包括：

-   掌握分布式训练相关系统组件的设计。

-   掌握常见的分布式训练方法：数据并行、模型并行和流水线并行。

-   掌握常见的分布式训练框架实现：集合通信和参数服务器。


```toc
:maxdepth: 2

overview
methods
cluster
collective
parameter_servers
summary
```